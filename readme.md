# ğŸš¦ CityFlux: Real-Time Event Streaming using Apache Kafka

CityFlux is a âš¡ real-time data streaming pipeline built to collect, process, and analyze urban mobility data such as ğŸš— vehicle telemetry, ğŸ“ GPS locations, ğŸŒ§ï¸ weather conditions, ğŸ“· traffic camera feeds, and ğŸš¨ emergency alerts.

---

## ğŸ§  Architecture Overview



---

## ğŸ”„ ETL Workflow

CityFlux leverages a modern, scalable ETL architecture:

1. **ğŸ“¥ Data Ingestion**  
   Simulated vehicle and environmental data is streamed into Apache Kafka topics in real time ğŸ›°ï¸.

2. **âš™ï¸ Data Processing**  
   Apache Spark reads the Kafka streams, performs necessary transformations (ETL), and writes structured data into Amazon S3 ğŸ“‚.

3. **ğŸ—ƒï¸ Data Cataloging**  
   AWS Glue Crawlers automatically scan raw and transformed S3 buckets and update the Glue Data Catalog for downstream querying.

4. **ğŸ“Š Querying & Warehousing**  
   - **Amazon Athena** allows SQL-based querying directly on the S3 data lake.
   - **Amazon Redshift Serverless** ingests curated data for high-performance analytics and dashboarding.

---

## ğŸ§° Tech Stack

| ğŸ”— Layer                  | âš™ï¸ Technology                         |
|--------------------------|--------------------------------------|
| ğŸ’¬ Streaming Engine       | Apache Kafka, Apache ZooKeeper       |
| ğŸ”„ Stream Processing      | Apache Spark                         |
| ğŸŒŠ Data Lake              | Amazon S3                            |
| ğŸ—‚ï¸ Metadata Catalog       | AWS Glue                             |
| ğŸ§  Query Engine           | Amazon Athena, Amazon Redshift       |
| ğŸ“ˆ Visualization Tools    | Power BI, AWS QuickSight             |
| ğŸ³ Containerization       | Docker                               |

---

## ğŸš€ Getting Started

### âœ… Prerequisites
- ğŸ³ Docker & Docker Compose  
- ğŸ”¥ Apache Spark  
- â˜ï¸ AWS CLI configured  
- ğŸ” AWS access to S3, Glue, Athena, Redshift  

---

### ğŸ“¥ 1. Clone the Repository
```bash
git clone https://github.com/Ajay1812/CityFlux-Event-Streaming-using-kafka.git
cd CityFlux-Event-Streaming-using-kafka
```

### ğŸ 2. Set Up Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate
```

### ğŸ“¦ 3. Install Dependencies
```bash
pip3 install -r requirements.txt
```

### ğŸ” 4. Configure AWS Credentials
Set up your AWS credentials in `config.py` ğŸ”.

```py
configuration = {
    "AWS_ACCESS_KEY" : "YOUR_ACCESS_KEY",
    "AWS_SECRET_KEY" : "YOUR_SECRET_KEY",
    "S3_BUCKET"      : "YOUR_SECRET_KEY" 
    }
```


### ğŸ³ 5. Start docker-compose
```bash
docker-compose up -d
```

### ğŸ“¡ 6. Simulate Raltime Data
Run the main script to simulate vehicle movements and stream data to Kafka:
```bash
python job/main.py
```

### ğŸ’¥ 7. Submit Spark Streaming Job
```bash
docker exec -it cityflux-event-streaming-using-kafka_spark-master_1 spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk:1.11.469 jobs/spark-job.py
```
## ğŸ¤ Contributing

Contributions are welcome! If you find a bug or want to enhance a project, feel free to submit a pull request.


## ğŸ“¬ Contact

Got questions or want to contribute? Feel free to reach out!

- ğŸ“§ **Email**: [a.kumar01c@gmail.com](mailto:a.kumar01c@gmail.com)  
- ğŸ”— **GitHub**: [Ajay1812](https://github.com/Ajay1812)
- ğŸŒ **LinkedIn**: [nf-analyst](https://www.linkedin.com/in/nf-analyst/)
